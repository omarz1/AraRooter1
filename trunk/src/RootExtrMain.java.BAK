// You have to add weka.jar and libsvm.jar to the build path in order to compile.
// ALL ARABIC TEXT MUST BE IN UTF-8, input files, etc
// this file is in utf-8
import java.io.IOException;
import java.util.ArrayList;
import java.util.Random;
import java.util.Scanner;
import java.util.StringTokenizer;
import java.util.regex.Pattern;
import java.io.BufferedReader;
import java.io.BufferedWriter;
import java.io.ByteArrayInputStream;
import java.io.File;
import java.io.FileNotFoundException;
import java.io.FileOutputStream;
import java.io.FileReader;
import java.io.FileWriter;
import java.io.ObjectOutputStream;
import java.io.PrintWriter;
import java.io.StringReader;

import weka.core.Instances;
import weka.core.converters.ArffSaver;
import weka.core.converters.CSVLoader;
import weka.core.converters.ConverterUtils.DataSource;
import weka.classifiers.Evaluation;
import weka.classifiers.functions.LibSVM;

public class RootExtrMain {
	
	// CONSTANTS
	public static final String FATHA = "ó";
	public static final String DAMMA = "õ";
	public static final String KASRA = "ö";
	public static final String SHADDA = "ø";
	public static final String ALIF = "Ç";
	public static final String HAMZMAD = "Â";
	public static final String HAMZA = "Á";
	public static final String[] DIACS_arr = {"ó","ð","õ","ñ","ö","ò","ø","ú"};
	public static final String DIACS_str = "óöðòõñúø";
	public static final String DIACS_regex = "[óöðòõñúø]";
	public static final int l = 3;
	public static final char group[][] = { 	
		{'Ç','Å','Ê','ã'},
		{'Ó','ä'},
		{'Ê','Ç','æ','í'},
		{'Ç','ä','æ','í','É'},
		{'Ç','ä','É'},
		{'Ç','É'},
		{0}
	};
	
	// to avoid recompiling regex's every iteration, we define them here 
	public static Pattern regex_newline = Pattern.compile("\\n");
	public static Pattern regex_hamza = Pattern.compile("[Á-Æ]");
	public static Pattern regex_letterShadda = Pattern.compile("([Á-í]"+SHADDA+")");
	public static Pattern regex_shadda = Pattern.compile(SHADDA);
	public static Pattern regex_hamzmad = Pattern.compile("Â");
	public static Pattern regex_allLetters = Pattern.compile("[Á-í]");
	public static Pattern regex_kashidaDiac = Pattern.compile("Ü([óöõú])");
	public static Pattern regex_allDiacs = Pattern.compile(DIACS_regex);
	public static Pattern regex_wawYa= Pattern.compile("[æí]");
	//return regex_.matcher(string).replaceAll("replace by");
	
	
	public static void main(String[]args) throws Exception {
		LibSVM[] svms = new LibSVM[l];
		
		// =======================READ========================
		/* <------- remove a '/' to skip the training 
		// if you have the model already trained from 
		// a previous run. the model can be found as 3 files
		// with extension .model.
		// 
		// ===================================================
		
		//===========================
		// FEATURE EXTRACTION
		//===========================

		// Read raw words from csv file previously cleaned by some regex operations
		//String rfName =  "ãÕÇÏÑ_ËáÇËíÉ.csv";
		String rfName =  "inMicro.csv";
		Scanner scnr = new Scanner (new File(rfName));
		ArrayList<String> sroots = new ArrayList<String>(30000); // this is too expensive and perhaps stupid..
		ArrayList<String> sderivs = new ArrayList<String>(30000); 
		int countLines = 0;
		while(scnr.hasNextLine()) {
			String tmp = scnr.nextLine().trim();
			countLines++;
			StringTokenizer x = new StringTokenizer(tmp, ",");
			if(x.countTokens() != 2) {
				System.out.println("Format error. "+rfName+":"+countLines+"\n  "+tmp);
				scnr.close();
				System.exit(0);
			}
			sroots.add(x.nextToken());
			sderivs.add(x.nextToken());
		}
		scnr.close();
		String[] roots = (String[]) sroots.toArray(new String[sroots.size()]);	
		String[] derivs = (String[]) sderivs.toArray(new String[sderivs.size()]);
		if(roots.length != derivs.length) {
			System.out.println("Input Format error. Num of roots different than num of derivs. How did this happen ?!!!");
			System.exit(0);
		}
		
		// some preprocessing
		for(int i=0; i<roots.length; i++) {
			roots[i] = hamzaNorm(roots[i]); // normalize hamza
			derivs[i] = hamzaNorm(derivs[i]); // normalize hamza
			derivs[i] = shaddaSub(derivs[i]); // resolve shadda
			derivs[i] = hamzmadSub(derivs[i]);// resolve hamzmad Â
		}
		
		
		// do feature extraction and
		// save the features to csv files, even though they will be directly used later, for convenience.
		String[] ffNames = {"feat1.csv","feat2.csv","feat3.csv"};
		if(l!=ffNames.length) {
			System.out.println("Wait wait... WHAT?!! Let me stop you here because, eventually, something will go wrong. I though we're dealing with 3 classifiers. I have "+l+" and "+ffNames.length);
			System.exit(0);
		}
		File[] files = new File[l];
		for(int i=0; i<l; i++) {
			files[i] = new File(ffNames[i]);
		}
		PrintWriter[] outs = new PrintWriter[l];
		for(int i=0; i<l; i++) {
			outs[i] = new PrintWriter(files[i]);
		}
		
		String[] derivFeats = getCsvFeats(derivs);
		// print unclassified datasets to files
		//for(int i=0; i<l; i++) {
		//	outs[i].print(featNamesCsv[i]); //print csv header
		//	outs[i].print(derivFeats[i]);
		//} // now we have 3 csv files with unclassified instances. you can clone these to use with your own evaluation function, but i'm using weka's 10-fold evaluation which uses the files with classified instances
		
		
		// append to outs[] the class for each instance
		for(int i=0; i<l; i++) {
			//append "Class", to the header
			String classLabel = ",Class\n";
			if(!derivFeats[i].contains("length")) {
				System.out.println("Warning.. feature csv files have no headers");
			}
			else {
				derivFeats[i] = derivFeats[i].replace("\\n",classLabel); // for the first line of headers
			}

			int li=1; // line iterator. starts form 1 to skip the csv header. line 0 is processed out of the loop
			String[] lines = derivFeats[i].split("\\n");
			if(lines.length != roots.length+1) {//+1 because of the header
				System.out.println("Error. something wrong not with the input but my processing.. with the number of lines in my roots and derivs arrays. I am expecting "+(roots.length+1)+" lines but found "+(lines.length-1));
				System.exit(0);
			}
			outs[i].print(lines[0]+classLabel);
			for(; li<lines.length; li++) { 
				outs[i].print(lines[li]+","+getInstanceClass(derivs[li-1],roots[li-1])[i]+"\n"); // for the rest of the file
			}
			outs[i].close();
		}
		
		//===========================
		// AFTER FEATURE EXTRACTION
		// TRAIN SVM
		//===========================
		
		// Read Data.. three datasets one for each letter of the root => three classifiers  
		DataSource[] sources = new DataSource[l];
		Instances[] data = new Instances[l];
		for(int i=0; i<l; i++) {
			sources[i] = new DataSource(ffNames[i]);
			data[i] = sources[i].getDataSet();
		}

		// setting class attribute if the data format does not provide this information
		for(int i=0; i<l; i++)
			if (data[i].classIndex() == -1) {
				data[i].setClassIndex(data[i].numAttributes()-1);
			}
			
		 
		// setup parameters for SVM
		String[] params = weka.core.Utils.splitOptions("-S 0 -K 2 -D 3 -G 0.0 -R 0.0 -N 0.5 -M 40.0 -C 1.0 -E 0.001 -P 0.1");
		
		
		// Evaluate SVM (optional to test your features and parameters)
		// evaluate using 10-fold.. test parameters
		// setup parameters.. see report for choice of parameters  
//		LibSVM svmEval = new LibSVM();
//		svmEval.setOptions(params);
//		Evaluation eval = new Evaluation(data1);
//		eval.crossValidateModel(svmEval, data1, 10, new Random(1));
//		System.out.println(eval.toSummaryString("\nResults\n======\n", false));
		
		// setup the three classifiers.. use the same parameters from evaluation
		for(int i=0; i<l; i++) {
			svms[i] = new LibSVM();
			svms[i].setOptions(params);
			svms[i].buildClassifier(data[i]);
		}
		
		//*/
		
		// load/save the trained models
		if(svms[0]==null) { 
			System.out.println("Loading models"); 
			String[] modelfn = new String[l];
			for(int i=0; i<l; i++) {
				modelfn[i] = "svm"+(i+1)+".model";
				svms[i] = (LibSVM) weka.core.SerializationHelper.read(modelfn[i]);
				System.out.println("Loaded svm model from "+modelfn[i]);
			}			
		} else { // save them 
			System.out.println("Saving models"); 
			String[] modelfn = new String[l];
			for(int i=0; i<l; i++) {
				modelfn[i] = "svm"+(i+1)+".model";
				weka.core.SerializationHelper.write(modelfn[i], svms[i]);
				System.out.println("Saved svm model in "+modelfn[i]);
			}			
		}
		//*
		//===========================
		//  AFTER Training
		//  CLASSIFY unseen instances
		//===========================
		// classify new instances.. use the trained classifiers
		// load unclassified data, note that everything will be done in threes because we have three feature sets
		// deriv is the string to be analyzed
		String deriv = "ÍãÇÑ";
		String[] fl = {"temp1.csv", "temp2.csv", "temp3.csv"};
		File[] tempFile = new File[l];
		for(int i=0; i<l; i++) {
			tempFile[i] = new File(fl[i]);
		}
		
		// get the features of our input
		String[] csvFeats = getCsvFeats(deriv);
		// convert them to ARFF
		// if the feats are in CSV format, they must be written
		// into a text file and then read again.. unfortunately,
		// this is how weka works; it is explicitly stated in the
		// documentation. 
		Instances[] unclassified = new Instances[l];
		for(int i=0; i<l; i++) {
			CSVLoader loader = new CSVLoader();
			loader.setSource(new ByteArrayInputStream(csvFeats[i].getBytes("UTF-8")));
			unclassified[i] = loader.getDataSet();
		    ArffSaver saver = new ArffSaver();
		    saver.setInstances(unclassified[i]);
		    saver.setFile(tempFile[i]);
		    saver.writeBatch();
		    unclassified[i] = new Instances(
                    new BufferedReader(
                      new FileReader(fl[i])));
		}

		// set class attribute
		for(int i=0; i<l; i++) 
			unclassified[i].setClassIndex(unclassified[i].numAttributes() - 1);
		 
		// create copy
		Instances labeled[] = new Instances[l];
		for(int i=0; i<l; i++)
			labeled[i] = new Instances(unclassified[i]);
		 
		// label instances
		for(int i=0; i<l; i++)
			for (int j=0; j<unclassified[i].numInstances(); j++) {
				double clsLabel = svms[i].classifyInstance(unclassified[i].instance(j));
				labeled[i].instance(j).setClassValue(clsLabel);
			}
		
		// show class
		for(int i=0; i<l; i++) {
			System.out.print(labeled[i]+" ");
		}
		for(int i=0; i<l; i++) {
			System.out.print(Integer.parseInt(labeled[i].toString())+" ");
		}
		
		// delete temp files
		for(int i=0; i<l; i++) {			
			tempFile[i].delete();
		}
		//*/
	}
	
	// returns the features of a given word in CSV format
	private static String[] getCsvFeats(String deriv)  throws FileNotFoundException {
		String[] h = featNamesCsv;
		String[] f = featExtract(deriv);
		if(h.length != f.length) System.out.println("HOW DID THIS HAPPEN ?!! DEBUG NOW");
		String[]ss = new String[h.length];
		for (int i=0; i<ss.length; i++) {
			ss[i] = h[i]+f[i];
		}
		return ss;
	}

	// returns the features of a given array of words in CSV format
	private static String[] getCsvFeats(String[] derivs)  throws FileNotFoundException {
		// append the header
		String[] h = featNamesCsv;
		String[]sss = new String[h.length];
		for (int i=0; i<sss.length; i++) { // for 3
			sss[i] = h[i];
		}
		// append the numbers
		for (int j=0; j<derivs.length; j++) { // for each deriv 
			String[] f = featExtract(derivs[j]);
			for(int i=0; i<sss.length; i++) // for 3
				sss[i] += f[i];
		}
		return sss;
	}
	private static String[] featNamesCsv = {
		"length,isLetter1InCorrespondingGroup,isLetter2InCorrespondingGroup,isLetter3InCorrespondingGroup,isLetter4InCorrespondingGroup,WhatLetter1Haraka,WhatLetter2Haraka,WhatLetter3Haraka,WhatLetter4Haraka,isLetter1Vowel,isLetter2Vowel,isLetter3Vowel,isLetter4Vowel,isLetter1Hamza,isLetter2Hamza,isLetter3Hamza,isLetter4Hamza\n",
		"length,isLetter2InCorrespondingGroup,isLetter3InCorrespondingGroup,isLetter4InCorrespondingGroup,isLetter5InCorrespondingGroup,WhatLetter2Haraka,WhatLetter3Haraka,WhatLetter4Haraka,WhatLetter5Haraka,isLetter2Vowel,isLetter3Vowel,isLetter4Vowel,isLetter5Vowel,isLetter2Hamza,isLetter3Hamza,isLetter4Hamza,isLetter5Hamza\n",
		"length,isLetter3InCorrespondingGroup,isLetter4InCorrespondingGroup,isLetter5InCorrespondingGroup,isLetter6InCorrespondingGroup,isLetter7InCorrespondingGroup,WhatLetter3Haraka,WhatLetter4Haraka,WhatLetter5Haraka,WhatLetter6Haraka,WhatLetter7Haraka,isLetter3Vowel,isLetter4Vowel,isLetter5Vowel,isLetter6Vowel,isLetter7Vowel,isLetter3Hamza,isLetter4Hamza,isLetter5Hamza,isLetter6Hamza,isLetter7Hamza\n"
	};
	
	private static String[] featNamesWClassCsv = {
		"length,isLetter1InCorrespondingGroup,isLetter2InCorrespondingGroup,isLetter3InCorrespondingGroup,isLetter4InCorrespondingGroup,WhatLetter1Haraka,WhatLetter2Haraka,WhatLetter3Haraka,WhatLetter4Haraka,isLetter1Vowel,isLetter2Vowel,isLetter3Vowel,isLetter4Vowel,isLetter1Hamza,isLetter2Hamza,isLetter3Hamza,isLetter4Hamza,Class\n",
		"length,isLetter2InCorrespondingGroup,isLetter3InCorrespondingGroup,isLetter4InCorrespondingGroup,isLetter5InCorrespondingGroup,WhatLetter2Haraka,WhatLetter3Haraka,WhatLetter4Haraka,WhatLetter5Haraka,isLetter2Vowel,isLetter3Vowel,isLetter4Vowel,isLetter5Vowel,isLetter2Hamza,isLetter3Hamza,isLetter4Hamza,isLetter5Hamza,Class\n",
		"length,isLetter3InCorrespondingGroup,isLetter4InCorrespondingGroup,isLetter5InCorrespondingGroup,isLetter6InCorrespondingGroup,isLetter7InCorrespondingGroup,WhatLetter3Haraka,WhatLetter4Haraka,WhatLetter5Haraka,WhatLetter6Haraka,WhatLetter7Haraka,isLetter3Vowel,isLetter4Vowel,isLetter5Vowel,isLetter6Vowel,isLetter7Vowel,isLetter3Hamza,isLetter4Hamza,isLetter5Hamza,isLetter6Hamza,isLetter7Hamza,Class\n"
	};
	
	// Extracts 3 feature vectors from the input string, one for each classifier
	// not every vector of the three is unique in features. For example, all three have
	// a feature "length" (length of deriv)
	// deriv is the word we want to find the root for.
	// This method should not be called directly
	private static String[] featExtract(String deriv) throws FileNotFoundException {
		
		// preprocess input string
		// ---------------------------
		String deriv_mod = deriv;
		deriv_mod = hamzaNorm(deriv_mod); // normalize hamza
		deriv_mod = shaddaSub(deriv_mod); // resolve shadda
		deriv_mod = hamzmadSub(deriv_mod);// resolve hamzmad Â
		// separate the string from its diacritical/vocalization/tashkeel marks  
		String noT = removeDiacs(deriv_mod); // the input string without Tashkeel
		String T = getDiacs(deriv_mod); // a string of only the Tashkeel of the input
		// DONE preprocess
		//----------------------------
		// prepare output
		// featVs is an array of 3 feature vectors each corresponding to a classifier.
		String featVs[] = {"","",""};
		
		featVs[0].concat((noT.length()+","));
		featVs[0].concat((isLetterInGroup(noT,1,1)+","));
		if(noT.equals("ÅÕáÇá")) {
				System.out.println(featVs[0]);
				System.exit(0);
		}
		
		// setup the vars to be distributed among the three feature vectors
		int m=7;
		int[] isLetterInGroup = new int[m];
		for(int i=0; i<m; i++) 
			isLetterInGroup[i] = isLetterInGroup(noT,i,i);
		int[] WhatLetterHaraka= new int[m];
		for(int i=0; i<m; i++) 
			WhatLetterHaraka[i] = WhatLetterHaraka(T,i);
		int[] isLetterVowel= new int[m];
		for(int i=0; i<m; i++) 
			isLetterVowel[i] = isLetterVowel(noT,i);
		int[] isLetterHamza= new int[m];
		for(int i=0; i<m; i++) 
			isLetterHamza[i] = isLetterHamza(noT,i);
		int j,f,t; // feat vector num, from, to
		
		// feature vector 1.. concerned letters (1-4)
		j=0; f=0; t=3;
		featVs[j] += noT.length()+",";
		for(int i=f; i<=t; i++) 
			featVs[j] += (isLetterInGroup[i]+",");
		for(int i=f; i<=t; i++) 
			featVs[j] += (WhatLetterHaraka[i]+",");
		for(int i=f; i<=t; i++) 
			featVs[j] += (isLetterVowel[i]+",");
		for(int i=f; i<=t; i++) 
			featVs[j] += (isLetterHamza[i]+",");
		featVs[j]=featVs[j].substring(0,featVs[j].length()-1); //remove last comma
		featVs[j] += "\n";
		
		// feature vector 2.. concerned letters (2-5)
		j=1; f=1; t=4;
		featVs[j] += noT.length()+",";
		for(int i=f; i<=t; i++) 
			featVs[j] += (isLetterInGroup[i]+",");
		for(int i=f; i<=t; i++) 
			featVs[j] += (WhatLetterHaraka[i]+",");
		for(int i=f; i<=t; i++) 
			featVs[j] += (isLetterVowel[i]+",");
		for(int i=f; i<=t; i++) 
			featVs[j] += (isLetterHamza[i]+",");
		featVs[j]=featVs[j].substring(0,featVs[j].length()-1); //remove last comma
		featVs[j] += "\n";
		
		// feature vector 3.. concerned letters (3-7)
		j=2; f=2; t=6;
		featVs[j] += noT.length()+",";
		for(int i=f; i<=t; i++) 
			featVs[j] += (isLetterInGroup[i]+",");
		for(int i=f; i<=t; i++) 
			featVs[j] += (WhatLetterHaraka[i]+",");
		for(int i=f; i<=t; i++) 
			featVs[j] += (isLetterVowel[i]+",");
		for(int i=f; i<=t; i++) 
			featVs[j] += (isLetterHamza[i]+",");
		featVs[j]=featVs[j].substring(0,featVs[j].length()-1); //remove last comma
		featVs[j] += "\n";
				
		System.out.println("Feats Extrctd from "+deriv_mod+" ( "+noT+" + "+T+" )"+"\n"+featVs[0]+featVs[1]+featVs[2]);
		return featVs;
	}
	
	// returns the class for this instance. used for setting up the training data
	private static String[] getInstanceClass(String deriv, String root) {
		// the class is a string for weka demands so
		String[] classes = new String[l];
		int pos = deriv.indexOf(root.charAt(0)) + 1; // +1 because 0 is reserved for 'not found'  
		if (pos>4) pos=0;
		classes[0]= "pos"+pos; 
		classes[1]= "pos"+locateLetter(root.charAt(1), deriv, 1); 
		classes[2]= "pos"+locateLetter(root.charAt(2), deriv, 2); 
		return classes;
		
	}
	
	// normalizes hamza replacing all forms by one
	private static String hamzaNorm(String string) {
		return regex_hamza.matcher(string).replaceAll("Á");		
	}

	// substitue a shadda by its equivalent
	//unfold shadda: a letter with shadda is equivalnet to two instances of the same letter, where the first has a sukoon
	private static String shaddaSub(String string) {
		string = regex_letterShadda.matcher(string).replaceAll("$1ú$1");
		string = regex_shadda.matcher(string).replaceAll("");
		return string;
	}
	
	// hamzmad (Â) replace by equivalent (hamza+mad) (ÁÇ)
	private static String hamzmadSub(String string) {
		return regex_hamzmad.matcher(string).replaceAll("ÁÇ");
	}
	
	// normalize vowel letters
	private static String vowelNorm(String string) {
		return regex_wawYa.matcher(string).replaceAll("Ç");
	}
	
	// returns string of diacs with indexes matching with letters they modify 
	private static String getDiacs(String string) {
		// if character is letter followed by diac, replace by diac
		// else replace by kashida
		// shadda should already be unfolded
		// tanween is not accounted for
		string = regex_allLetters.matcher(string).replaceAll("Ü");
		string = regex_kashidaDiac.matcher(string).replaceAll("$1");
		return string;
	}
	
	// returns the word unvocalized (undiacritized)
	public static String removeDiacs(String string) {
		return regex_allDiacs.matcher(string).replaceAll("");
	}
	
	// is the character a diacritical sign/ a vocalization mark
	public static boolean isDiac(char c) {
		return DIACS_str.indexOf(c) > -1;
	}

	private static int WhatLetterHaraka(String T, int i) {
		// we want zero to mean don't care.. but how
		try { 
			if(  T.charAt(i) == 'ó' )
				return 1;
			else if(T.charAt(i) == 'ö')
				return 2;
			else if(T.charAt(i) == 'õ')
				return 3;
			else if(T.charAt(i) == 'ú')
				return 4;
		}
		catch(Exception e ) { return 0; }
		return 0;
	}

	private static int locateLetter(char toLocate, String toSearch, int from, int to) {
		try { return toSearch.substring(from,to).indexOf(toLocate)+from;
		} catch (StringIndexOutOfBoundsException e) {
			return -1;
		}
	}

	private static int locateLetter(char toLocate, String toSearch, int from) {
		int loc = toSearch.indexOf(toLocate, from);
		if(loc == -1) return loc;
		else return loc;
	}

	private static int isLetterVowel(String noT, int i) {
		try { if(  noT.charAt(i) == 'Ç'
				|| noT.charAt(i) == 'æ'
				|| noT.charAt(i) == 'í'
				|| noT.charAt(i) == 'ì')
			return 1; }
	catch(Exception e ) { return -1; }
		 return 0;
	}

	private static int isLetterHamza(String noT, int i) {
		try { if(  noT.charAt(i) == 'Á'
				|| noT.charAt(i) == 'Æ'
				|| noT.charAt(i) == 'Ä'
				|| noT.charAt(i) == 'Ã'
			    || noT.charAt(i) == 'Å')
			return 1; }
		catch(Exception e ) { return -1; }
		 return 0;
	}

	private static int isLetterInGroup(String s, int i, int j) {
		try { for (int x=0; x<group[j].length; x++) {
			if(s.charAt(i)==group[j][x])
				return 1; 
		} }
		catch(Exception e ) { return -1; }
		return 0;
	}
	
	// a guesser to return true if deriv is likely derived from root
	public static boolean guessDerived(String deriv, String root) {
		// deriv is the word to be tested whether it is derived from root
		//Text Normalization
		root  = hamzaNorm(root);// normalize hamza
		deriv = hamzaNorm(deriv);// normalize hamza
		root  = vowelNorm(root); // normalize vowels
		deriv = vowelNorm(deriv); // normalize vowels
		deriv = shaddaSub(deriv); //unfold shadda
		deriv = removeDiacs(deriv); //remove tashkeel
		deriv = hamzmadSub(deriv); // equiv Â
		
		// The guesser
		boolean success = false;
		for(int i=0; i<root.length()-1; i++) {
			try {
				int ti1 = deriv.indexOf(root.charAt(i));
				int ti2 = deriv.indexOf(root.charAt(i+1)); 
				if(ti1 < ti2 && ti1 > -1) 
					success = true;
				else
					return false;
			} catch (StringIndexOutOfBoundsException e) {return false;}
		}
		return success;
	}

}

